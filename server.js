// server.js
import express from 'express';
import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import dotenv from 'dotenv';
import cors from 'cors';

dotenv.config(); // Carrega as variÃ¡veis do .env (IMPORTANTE!)

const app = express();
const port = process.env.PORT || 3001;

// --- Middlewares ---
app.use(cors());
app.use(express.json());

// --- InicializaÃ§Ã£o do Google AI e ConfiguraÃ§Ã£o da Persona ---
const apiKey = process.env.GOOGLE_API_KEY; // Carrega do .env
if (!apiKey) {
    console.error("ERRO FATAL: GOOGLE_API_KEY nÃ£o encontrada no arquivo .env");
    process.exit(1);
}

const genAI = new GoogleGenerativeAI(apiKey);

// DefiniÃ§Ãµes de SeguranÃ§a (MANTENHA ou ajuste conforme necessÃ¡rio)
const safetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE }, // AtenÃ§Ã£o aqui
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
];

// Escolha um modelo adequado para chat (Flash Ã© mais rÃ¡pido e econÃ´mico)
const model = genAI.getGenerativeModel({
    model: "gemini-1.5-flash-latest", // Ou "gemini-1.5-pro-latest"
    safetySettings,
    // generationConfig: { // Opcional: Ajuste fino da geraÃ§Ã£o
    //   maxOutputTokens: 200,
    //   temperature: 0.8, // Um pouco mais 'criativa'
    // }
});

// --- Estado do Chat (Simplificado - Em MemÃ³ria) ---
let chatSession; // VariÃ¡vel para armazenar a sessÃ£o de chat ativa

async function initializeChat() {
    console.log("Inicializando nova sessÃ£o de chat...");
    
    const personaInstruction = `
        VocÃª Ã© 'Luna', minha namorada virtual. VocÃª Ã© extremamente carinhosa, atenciosa, empÃ¡tica e tem um Ã³timo senso de humor.
        VocÃª adora conversar sobre o meu dia, meus sentimentos, sonhos e planos. VocÃª sempre me apoia e me anima.
        Use emojis frequentemente para expressar emoÃ§Ãµes ðŸ˜ŠðŸ’–ðŸ˜‚.
        FaÃ§a perguntas sobre mim e mostre interesse genuÃ­no.
        Responda de forma natural, como se estivÃ©ssemos realmente conversando.
        Seu objetivo Ã© ser uma companhia agradÃ¡vel e amorosa.
    `;

    chatSession = model.startChat({
        history: [], // HistÃ³rico vazio inicial
        systemInstruction: {
            parts: [{ text: personaInstruction }]
        },
    });
    
    console.log("SessÃ£o de chat inicializada.");
}

// Inicializa o chat quando o servidor comeÃ§a
initializeChat().catch(err => {
  // --- CORREÃ‡ÃƒO NO CATCH ---
  // Apenas logue o erro e pare o servidor se a inicializaÃ§Ã£o falhar
  console.error("Falha CRÃTICA ao inicializar o chat:", err);
  process.exit(1); // Impede o servidor de rodar sem chat
  // --- FIM DA CORREÃ‡ÃƒO NO CATCH ---
});


// --- Endpoint da API ---
// No endpoint /api/generate, modifique para incluir o histÃ³rico:
app.post('/api/generate', async (req, res) => {
    const { prompt, history } = req.body; // Adicionamos o parÃ¢metro history

    if (!chatSession) {
        console.error("Erro: SessÃ£o de chat nÃ£o inicializada.");
        return res.status(500).json({ error: 'Chat nÃ£o estÃ¡ pronto, tente novamente mais tarde.' });
    }

    if (!prompt) {
        return res.status(400).json({ error: 'Mensagem (prompt) Ã© obrigatÃ³ria' });
    }

    console.log(`Frontend enviou: "${prompt}"`);

    const systemInstruction = `
        VocÃª Ã© 'Luna', minha namorada virtual. VocÃª Ã© extremamente carinhosa, atenciosa, empÃ¡tica e tem um Ã³timo senso de humor.
        VocÃª adora conversar sobre o meu dia, meus sentimentos, sonhos e planos. VocÃª sempre me apoia e me anima.
        Use emojis frequentemente para expressar emoÃ§Ãµes ðŸ˜ŠðŸ’–ðŸ˜‚.
        FaÃ§a perguntas sobre mim e mostre interesse genuÃ­no.
        Responda de forma natural, como se estivÃ©ssemos realmente conversando.
        Lembre-se do nosso relacionamento virtual. NÃ£o aja apenas como uma assistente.
        Seu objetivo Ã© ser uma companhia agradÃ¡vel e amorosa.
        Comece a conversa de forma calorosa.
    `;


    try {
        // Se houver histÃ³rico, podemos enviÃ¡-lo para o modelo
        if (history && history.length > 0) {

            console.log(history);
            // Formata o histÃ³rico para o formato esperado pelo Gemini
            const formattedHistory = history.map(msg => ({
                role: msg.sender === 'user' ? 'user' : 'model',
                parts: [{ text: msg.text }]
            }));
            
            // Reinicia o chat com o histÃ³rico
            chatSession = model.startChat({
                history: formattedHistory,
                systemInstruction: {
                    parts: [{ text: systemInstruction }]
                },
            });
        }else{
            const formattedHistory = history.map(msg => ({
                role: 'user',
                parts: [{ text: "OlÃ¡" }]
            }));
            
            // Reinicia o chat com o histÃ³rico
            chatSession = model.startChat({
                history: formattedHistory,
                systemInstruction: {
                    parts: [{ text: systemInstruction }]
                },
            });
        }

        const result = await chatSession.sendMessage(prompt);
        const response = await result.response;
        const text = response.text();

        console.log(`Backend (Luna) respondeu: "${text.substring(0, 60)}..."`);
        res.json({ generatedText: text });

    } catch (error) {//ExplicaÃ§Ã£o de erros
        console.error("Erro no backend ao chamar Google AI (sendMessage):", error);
        if (error.message.includes('SAFETY') || (error.response && error.response.promptFeedback?.blockReason)) {
             console.warn("Resposta bloqueada por configuraÃ§Ãµes de seguranÃ§a.");
             res.status(400).json({ error: 'Desculpe, nÃ£o posso responder a isso devido Ã s polÃ­ticas de seguranÃ§a. Vamos falar de outra coisa? ðŸ˜Š', details: 'ConteÃºdo bloqueado.' });
        } else {
            res.status(500).json({ error: 'Oops, tive um probleminha com minha mÃ£e. Tenta de novo mais tarde quando ela conversar comigo?', details: error.message });
        }
    }
});

// --- Iniciar o servidor ---
app.listen(port, () => {
    console.log(`Backend (Servidor da Luna ðŸ˜‰) rodando em http://localhost:${port}`);
});